{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967a22e0-f910-46a2-950f-63e6806897d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout, GRU, LayerNormalization, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f0f1cc-342b-4710-a870-f63502774a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7069 - loss: 0.7375 - val_accuracy: 0.8333 - val_loss: 0.8066\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8584 - loss: 0.3653 - val_accuracy: 0.9000 - val_loss: 0.7012\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2847 - val_accuracy: 0.9667 - val_loss: 0.6297\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2406 - val_accuracy: 1.0000 - val_loss: 0.5703\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.2582 - val_accuracy: 1.0000 - val_loss: 0.5112\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2335 - val_accuracy: 1.0000 - val_loss: 0.4550\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1630 - val_accuracy: 1.0000 - val_loss: 0.4012\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.1835 - val_accuracy: 1.0000 - val_loss: 0.3656\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.2220 - val_accuracy: 1.0000 - val_loss: 0.3491\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1250 - val_accuracy: 1.0000 - val_loss: 0.3005\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.1337 - val_accuracy: 1.0000 - val_loss: 0.2717\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9590 - loss: 0.0998 - val_accuracy: 1.0000 - val_loss: 0.2327\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.1040 - val_accuracy: 0.9667 - val_loss: 0.2126\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1079 - val_accuracy: 0.9333 - val_loss: 0.2236\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0728 - val_accuracy: 0.9333 - val_loss: 0.1995\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9592 - loss: 0.0861 - val_accuracy: 0.9333 - val_loss: 0.1547\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0830 - val_accuracy: 0.9667 - val_loss: 0.1321\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1086 - val_accuracy: 0.9667 - val_loss: 0.1405\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1379 - val_accuracy: 0.9333 - val_loss: 0.1485\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.1135 - val_accuracy: 0.9333 - val_loss: 0.1875\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0941 - val_accuracy: 0.9667 - val_loss: 0.1110\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0810 - val_accuracy: 0.9667 - val_loss: 0.0846\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1849 - val_accuracy: 0.9667 - val_loss: 0.0937\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1247 - val_accuracy: 0.9667 - val_loss: 0.0831\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.1487 - val_accuracy: 0.9667 - val_loss: 0.0912\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.0875 - val_accuracy: 0.9667 - val_loss: 0.0730\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0583 - val_accuracy: 0.9667 - val_loss: 0.0730\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0414 - val_accuracy: 0.9667 - val_loss: 0.0772\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0898 - val_accuracy: 0.9667 - val_loss: 0.0890\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0377 - val_accuracy: 0.9667 - val_loss: 0.0810\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0367 - val_accuracy: 0.9667 - val_loss: 0.0569\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0456 - val_accuracy: 1.0000 - val_loss: 0.0478\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1058 - val_accuracy: 0.9667 - val_loss: 0.0707\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.1019 - val_accuracy: 0.9667 - val_loss: 0.0605\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0558 - val_accuracy: 1.0000 - val_loss: 0.0453\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0453\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1317 - val_accuracy: 0.9667 - val_loss: 0.0705\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0638 - val_accuracy: 1.0000 - val_loss: 0.0441\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.1514 - val_accuracy: 0.9333 - val_loss: 0.0869\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.0880 - val_accuracy: 0.9667 - val_loss: 0.0471\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0757 - val_accuracy: 0.9667 - val_loss: 0.0508\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9524 - loss: 0.1218 - val_accuracy: 1.0000 - val_loss: 0.0392\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0446 - val_accuracy: 1.0000 - val_loss: 0.0362\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0617 - val_accuracy: 1.0000 - val_loss: 0.0303\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.1116 - val_accuracy: 1.0000 - val_loss: 0.0429\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0562 - val_accuracy: 1.0000 - val_loss: 0.0502\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0427 - val_accuracy: 1.0000 - val_loss: 0.0424\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0638 - val_accuracy: 1.0000 - val_loss: 0.0300\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0419 - val_accuracy: 1.0000 - val_loss: 0.0205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0205\n",
      "Test accuracy (IRIS): 100.00%\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Zadanie 1: Klasyfikacja IRIS z Siecią Gęstą i BatchNormalization\n",
    "# ===========================\n",
    "\n",
    "# Załadowanie danych IRIS\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "# Podział na dane treningowe i testowe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Model sieci gęstej z BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input\n",
    "\n",
    "# Stosujemy warstwę Input na początku modelu\n",
    "model_iris = Sequential()\n",
    "model_iris.add(Input(shape=(4,)))  # Warstwa wejściowa (4 cechy IRIS)\n",
    "model_iris.add(Dense(64, activation='relu'))  # Warstwa gęsta\n",
    "model_iris.add(BatchNormalization())  # Warstwa BatchNormalization\n",
    "model_iris.add(Dense(32, activation='relu'))\n",
    "model_iris.add(Dense(3, activation='softmax'))  # Warstwa wyjściowa (3 klasy)\n",
    "\n",
    "# Kompilacja i trenowanie modelu\n",
    "model_iris.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_iris.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Ewaluacja modelu\n",
    "loss, accuracy = model_iris.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy (IRIS): {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd26a96-cb15-4c6e-aa61-7af7d1dc0f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.3301 - val_accuracy: 0.9801 - val_loss: 0.0619\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0573 - val_accuracy: 0.9861 - val_loss: 0.0427\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0365 - val_accuracy: 0.9860 - val_loss: 0.0417\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0244 - val_accuracy: 0.9835 - val_loss: 0.0490\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0179 - val_accuracy: 0.9878 - val_loss: 0.0383\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0149 - val_accuracy: 0.9890 - val_loss: 0.0369\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.9881 - val_loss: 0.0395\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9888 - val_loss: 0.0374\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9873 - val_loss: 0.0490\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9887 - val_loss: 0.0453\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9842 - loss: 0.0597  \n",
      "Test accuracy (MNIST): 98.87%\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Zadanie 2: Klasyfikacja cyfr MNIST z większymi jądrami konwolucyjnymi\n",
    "# ===========================\n",
    "\n",
    "# Załadowanie danych MNIST\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Input\n",
    "\n",
    "# Wczytanie danych\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Zmiana kształtu danych wejściowych (dodanie wymiaru kanału 1 dla obrazów szaro-skalowych)\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# Normalizacja danych\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# One-hot encoding etykiet\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Model z warstwą konwolucyjną\n",
    "model_mnist = Sequential()\n",
    "model_mnist.add(Input(shape=(28, 28, 1)))  # Warstwa wejściowa (rozmiar obrazu 28x28, 1 kanał)\n",
    "model_mnist.add(Conv2D(32, (5, 5), activation='relu'))  # Warstwa konwolucyjna z jądrem 5x5\n",
    "model_mnist.add(MaxPooling2D(pool_size=(2, 2)))  # Max pooling\n",
    "model_mnist.add(Flatten())  # Spłaszczanie wyników\n",
    "model_mnist.add(Dense(128, activation='relu'))  # Warstwa gęsta\n",
    "model_mnist.add(Dense(10, activation='softmax'))  # Warstwa wyjściowa (10 klas)\n",
    "\n",
    "# Kompilacja i trenowanie modelu\n",
    "model_mnist.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_mnist.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Ewaluacja modelu\n",
    "loss, accuracy = model_mnist.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy (MNIST): {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b650db05-2523-4220-ae27-5d4c8a6fb5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4422\n",
      "Epoch 2/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1706\n",
      "Epoch 3/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0654\n",
      "Epoch 4/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0461\n",
      "Epoch 5/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0404\n",
      "Epoch 6/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0229\n",
      "Epoch 7/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0138\n",
      "Epoch 8/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110\n",
      "Epoch 9/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117\n",
      "Epoch 10/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0113\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "Pierwsze prognozy: [[ 0.00698585]\n",
      " [-0.24499094]\n",
      " [-0.48419213]\n",
      " [-0.6633777 ]\n",
      " [-0.7823252 ]]\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Zadanie 3: Prognozowanie sekwencji przy użyciu GRU z warstwą Dropout\n",
    "# ===========================\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dropout, Dense, Input\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# Generowanie sztucznych danych sekwencyjnych\n",
    "data = np.sin(np.linspace(0, 100, 1000))  # Sztuczne dane - funkcja sinusoidalna\n",
    "targets = np.roll(data, -1)  # Prognozowanie kolejnych wartości\n",
    "targets[-1] = data[-1]  # Ostatnia wartość celu\n",
    "\n",
    "# Przygotowanie danych do treningu (z pomocą TimeseriesGenerator)\n",
    "sequence_length = 50  # Długość sekwencji wejściowej\n",
    "generator = TimeseriesGenerator(data, targets, length=sequence_length, batch_size=32)\n",
    "\n",
    "# Model z warstwą GRU\n",
    "model_gru = Sequential()\n",
    "model_gru.add(Input(shape=(sequence_length, 1)))  # Warstwa wejściowa (sekwencja długości 50)\n",
    "model_gru.add(GRU(64, activation='relu'))  # Warstwa GRU\n",
    "model_gru.add(Dropout(0.2))  # Warstwa Dropout\n",
    "model_gru.add(Dense(1))  # Warstwa wyjściowa (prognoza jednej wartości)\n",
    "\n",
    "# Kompilacja modelu\n",
    "model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Trening modelu\n",
    "model_gru.fit(generator, epochs=10)\n",
    "\n",
    "# Prognozowanie na danych testowych\n",
    "test_data = np.sin(np.linspace(100, 120, 100))  # Testowe dane\n",
    "test_generator = TimeseriesGenerator(test_data, test_data, length=sequence_length, batch_size=32)\n",
    "\n",
    "# Wywołanie predict bez argumentów związanych z wieloprocesowością\n",
    "predictions = model_gru.predict(test_generator)\n",
    "\n",
    "# Wyświetlanie pierwszych kilku prognoz\n",
    "print(f\"Pierwsze prognozy: {predictions[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d1e0f5-e680-49e7-ba6c-9412eb9bb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.8402\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2445 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6319 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3776 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2069 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1814 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1561 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1483 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1433 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1131 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Pierwsze prognozy: [[[0.28944317]\n",
      "  [0.4014288 ]\n",
      "  [0.49978384]\n",
      "  [0.42256597]\n",
      "  [0.50786173]\n",
      "  [0.3463941 ]\n",
      "  [0.51711893]\n",
      "  [0.6571032 ]\n",
      "  [0.45677057]\n",
      "  [0.3832771 ]]\n",
      "\n",
      " [[0.540481  ]\n",
      "  [0.4235727 ]\n",
      "  [0.13946886]\n",
      "  [0.6808267 ]\n",
      "  [0.52350956]\n",
      "  [0.3749635 ]\n",
      "  [0.55630755]\n",
      "  [0.66051346]\n",
      "  [0.42626962]\n",
      "  [0.6213175 ]]\n",
      "\n",
      " [[0.45441017]\n",
      "  [0.53836185]\n",
      "  [0.6687996 ]\n",
      "  [0.54372895]\n",
      "  [0.51846945]\n",
      "  [0.48706612]\n",
      "  [0.56204987]\n",
      "  [0.58986545]\n",
      "  [0.51089317]\n",
      "  [0.48925003]]\n",
      "\n",
      " [[0.414041  ]\n",
      "  [0.5310236 ]\n",
      "  [0.7494235 ]\n",
      "  [0.5361346 ]\n",
      "  [0.45250866]\n",
      "  [0.57787263]\n",
      "  [0.5628777 ]\n",
      "  [0.4776264 ]\n",
      "  [0.40017447]\n",
      "  [0.18394859]]\n",
      "\n",
      " [[0.60435855]\n",
      "  [0.44212607]\n",
      "  [0.4563798 ]\n",
      "  [0.2787672 ]\n",
      "  [0.54331326]\n",
      "  [0.43808737]\n",
      "  [0.40974176]\n",
      "  [0.535267  ]\n",
      "  [0.4645554 ]\n",
      "  [0.30843037]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LayerNormalization, Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "# Zadanie 4: Wprowadzenie dwóch bloków Transformer Encoder\n",
    "# ===========================\n",
    "\n",
    "# Prosty model Transformer Encoder\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.norm1 = LayerNormalization()\n",
    "        self.norm2 = LayerNormalization()\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)  # Multi-head attention\n",
    "        out1 = self.norm1(attn_output + inputs)  # Residual connection and layer normalization\n",
    "        ffn_output = self.ffn(out1)  # Feedforward network\n",
    "        out2 = self.norm2(ffn_output + out1)  # Another residual connection and normalization\n",
    "        return out2\n",
    "\n",
    "# Przygotowanie danych (np. dla tekstu lub sekwencji)\n",
    "X_transformer = np.random.rand(100, 10, 64)  # Przykładowe dane: 100 próbek, 10 timesteps, 64 cechy\n",
    "y_transformer = np.random.rand(100, 1)  # Przykładowe dane: 100 próbek, 1 wynik\n",
    "\n",
    "# Model z Transformer Encoder\n",
    "inputs = Input(shape=(10, 64))\n",
    "x = TransformerEncoder(num_heads=2, key_dim=64)(inputs)\n",
    "x = Dense(1)(x)  # Warstwa wyjściowa (np. regresja)\n",
    "model_transformer = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Kompilacja i trenowanie modelu\n",
    "model_transformer.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_transformer.fit(X_transformer, y_transformer, epochs=10, batch_size=32)\n",
    "\n",
    "# Predykcja\n",
    "y_pred_transformer = model_transformer.predict(X_transformer)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "print(f\"Pierwsze prognozy: {y_pred_transformer[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901cb90-e5d8-462c-afe3-dbf4361667ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
